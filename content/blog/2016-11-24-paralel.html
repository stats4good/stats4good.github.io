---
author: "Douglas R. Mesquita Azevedo"
title: "Paralelização"
date: "2016-11-24"
categories: ["Tutoriais R"]
slug: "paralel"
tags: ["R", "Paralelização"]
draft: false
banner: "img/banners/paralel.jpg"
summary: "Cansado de perder horas para rodar vários modelos ou muitas simulações? Neste post ajudaremos você a economizar seu tempo mostrando aspectos básicos de programação em paralelo utilizando o R."
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/plotlyjs/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plotlyjs/plotly-latest.min.js"></script>
<script src="/rmarkdown-libs/plotly-binding/plotly.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<script src="/rmarkdown-libs/typedarray/typedarray.min.js"></script>


<center>
<img src="/rmarkdown-libs/figures-html/save-time.jpg" />
</center>
<div id="paralelizacao-e-programacao-em-gpu-aspectos-basicos" class="section level1">
<h1><span style="color:#2f8fcc">Paralelização e programação em GPU: Aspectos básicos</span></h1>
<p><span style="color:#2f8fcc">Douglas R. Mesquita Azevedo</span></p>
<p>Neste post trabalharemos aspectos básicos de programação em paralelo utilizando o <em>software</em> R. Para isso, serão necessários os pacotes <em>doMC</em>, <em>parallel</em> e <em>foreach</em> para programação utilizando os processadores da máquina, e para a programação utilizando uma placa gráfica (GPU) traremos alguns aspectos introdutórios.</p>
<div id="computacao-paralela" class="section level2">
<h2><span style="color:#2f8fcc">Computação paralela</span></h2>
<p>O assunto computação paralela data de 1958 quando John Cocke e Daniel Slotnick discutiram o uso do paralelismo para cálculos numéricos pela primeira vez na IBM.</p>
<p>Segundo a <a href="https://pt.wikipedia.org/wiki/Computa%C3%A7%C3%A3o_paralela">Wikipedia</a> Computação paralela é uma forma de computação em que vários cálculos são realizados ao mesmo tempo, operando sob o princípio de que grande problemas geralmente podem ser divididos em problemas menores, que então são resolvidos concorrentemente (em paralelo).</p>
<p>Naturalmente paralelizamos processos no nosso dia-a-dia. Por exemplo, quando trabalhamos em uma empresa, divide-se o problema em pequenas partes em que cada parte é executada por um grupo de forma paralela. Dentro deste grupo ainda é possível subdividir a parte do problema em subtarefas que também podem ser executadas de forma paralela.</p>
<p>Desta forma, computação em paralelo foge do pensamento sequencial (quando possível). Por exemplo, para calcular a média de idade de cada curso de graduação da UFMG, não é necessário que os cálculos sejam realizados de forma sequencial, pois, a média de idade de um curso não influencia na média de idade de um outro curso e portanto neste caso podemos <em>paralelizar</em> o cálculo. Já quando estamos trabalhando com um problema iterativo em que o valor corrente depende do valor imediatamente anterior não é possível paralelizar a computação (Ex: Gibbs Sampling).</p>
<p>A computação em paralelo depende de quantos processadores você dispoem, de forma que quanto maior o número de processadores maior a capacidade de executar processos simultaneamente. Existem duas leis que mensuram o aumento de velocidade de computação utilizando programação em paralelo.</p>
<p>A lei de Amdahl é dada por <span class="math inline">\(\displaystyle S = \frac{1}{1-P+\frac{P}{S_P}}\)</span>, em que S é a aceleração na execução do processo com a paralelização, <span class="math inline">\(P\)</span> é a fração paralelizável do código e <span class="math inline">\(S_P\)</span> é o tempo de execução da parte paralelizável (com a melhoria). Por exemplo, se 30% do código é paralelizável e com a melhoria esta parte o código é executada duas vezes mais rápido, então o aumento de velocidade de computação é dado por <span class="math inline">\(\displaystyle S = \frac{1}{1-0.3+\frac{0.3}{2}} = 1.18\)</span>. Ou seja um código que é executado em 590 segundos sem paralelização, teria o tempo de computação reduzido para 500 segundos.</p>
<p>Outra forma de estimar a aceleração na execução do processo é dada pela lei de Gustafson definida por <span class="math inline">\(S = 1-P+P*S_P\)</span>. Abaixo um gráfico contrapondo as duas curvas em um caso específico.</p>
<pre class="r"><code>library(ggplot2)
library(plotly)
library(ggthemes)

#--- Parâmetros gráficos

colAxis &lt;- grey(0.4)
colTitle &lt;- grey(0.2)
colPoints &lt;- &quot;#0b5394&quot;
colLine &lt;- &quot;IndianRed&quot;
colGroup1 &lt;- &quot;#1F77B4&quot;
colGroup2 &lt;- &quot;#D62728&quot;
colBack &lt;- &quot;white&quot;
sizePoint &lt;- 2
sizeLine &lt;- 1.3

tema &lt;- theme_stata() +
  theme(axis.title = element_text(size = 12, margin = margin(10,10,0,0)),
        axis.text = element_text(size = 12, colour = colAxis),
        panel.background = element_rect(fill = colBack),
        plot.background = element_rect(fill = colBack))

#--- Leis de A  mdahl e Gustafson
s_1 &lt;- function(p, s) 1/(1-p+p/s)
s_2 &lt;- function(p, s) 1-p+p*s

seq_proc &lt;- seq(1, 15)
p_1 &lt;- 0.70
p_2 &lt;- 0.30

df_proc &lt;- data.frame(n_proc = rep(seq_proc, 4),
                      S = c(s_1(p = p_1, s = seq_proc), 
                            s_1(p = p_2, s = seq_proc),
                            s_2(p = p_1, s = seq_proc),
                            s_2(p = p_2, s = seq_proc)),
                      p = paste0(&quot;P = &quot;, rep(c(p_1, p_2), 2, each = length(seq_proc))),
                      Tipo = rep(c(rep(&quot;Amdahl&quot;, length(seq_proc)), rep(&quot;Gustafson&quot;, length(seq_proc))), each = 2))

gg_proc &lt;- ggplot(data = df_proc, aes(x = n_proc, y = S, colour = Tipo)) +
  geom_line(size = sizeLine) +
  scale_color_manual(&quot;&quot;, values = c(&quot;Amdahl&quot; = &quot;Steelblue&quot;,
                                    &quot;Gustafson&quot; = &quot;IndianRed&quot;)) +
  xlab(&quot;Número de processadores&quot;) +
  ylab(&quot;Aceleração de processamento&quot;) +
  tema +
  theme(legend.position = &quot;top&quot;) +
  facet_wrap(~p)

ggplotly(gg_proc)</code></pre>
<pre><code>## Warning: We recommend that you use the dev version of ggplot2 with `ggplotly()`
## Install it with: `devtools::install_github(&#39;hadley/ggplot2&#39;)`</code></pre>
<center>
<pre><code>## Warning: We recommend that you use the dev version of ggplot2 with `ggplotly()`
## Install it with: `devtools::install_github(&#39;hadley/ggplot2&#39;)`</code></pre>
<div id="14ac27d3b950" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="14ac27d3b950">{"x":{"data":[{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[1,1.17647058823529,1.25,1.29032258064516,1.31578947368421,1.33333333333333,1.34615384615385,1.35593220338983,1.36363636363636,1.36986301369863,1.375,1.37931034482759,1.38297872340426,1.38613861386139,1.38888888888889],"text":["n_proc:  1<br />S:  1.000000<br />Tipo: Amdahl","n_proc:  2<br />S:  1.176471<br />Tipo: Amdahl","n_proc:  3<br />S:  1.250000<br />Tipo: Amdahl","n_proc:  4<br />S:  1.290323<br />Tipo: Amdahl","n_proc:  5<br />S:  1.315789<br />Tipo: Amdahl","n_proc:  6<br />S:  1.333333<br />Tipo: Amdahl","n_proc:  7<br />S:  1.346154<br />Tipo: Amdahl","n_proc:  8<br />S:  1.355932<br />Tipo: Amdahl","n_proc:  9<br />S:  1.363636<br />Tipo: Amdahl","n_proc: 10<br />S:  1.369863<br />Tipo: Amdahl","n_proc: 11<br />S:  1.375000<br />Tipo: Amdahl","n_proc: 12<br />S:  1.379310<br />Tipo: Amdahl","n_proc: 13<br />S:  1.382979<br />Tipo: Amdahl","n_proc: 14<br />S:  1.386139<br />Tipo: Amdahl","n_proc: 15<br />S:  1.388889<br />Tipo: Amdahl"],"type":"scatter","mode":"lines","line":{"width":4.91338582677165,"color":"rgba(70,130,180,1)","dash":"solid"},"hoveron":"points","name":"Amdahl","legendgroup":"Amdahl","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[1,1.53846153846154,1.875,2.10526315789474,2.27272727272727,2.4,2.5,2.58064516129032,2.64705882352941,2.7027027027027,2.75,2.7906976744186,2.82608695652174,2.85714285714286,2.88461538461538],"text":["n_proc:  1<br />S:  1.000000<br />Tipo: Amdahl","n_proc:  2<br />S:  1.538462<br />Tipo: Amdahl","n_proc:  3<br />S:  1.875000<br />Tipo: Amdahl","n_proc:  4<br />S:  2.105263<br />Tipo: Amdahl","n_proc:  5<br />S:  2.272727<br />Tipo: Amdahl","n_proc:  6<br />S:  2.400000<br />Tipo: Amdahl","n_proc:  7<br />S:  2.500000<br />Tipo: Amdahl","n_proc:  8<br />S:  2.580645<br />Tipo: Amdahl","n_proc:  9<br />S:  2.647059<br />Tipo: Amdahl","n_proc: 10<br />S:  2.702703<br />Tipo: Amdahl","n_proc: 11<br />S:  2.750000<br />Tipo: Amdahl","n_proc: 12<br />S:  2.790698<br />Tipo: Amdahl","n_proc: 13<br />S:  2.826087<br />Tipo: Amdahl","n_proc: 14<br />S:  2.857143<br />Tipo: Amdahl","n_proc: 15<br />S:  2.884615<br />Tipo: Amdahl"],"type":"scatter","mode":"lines","line":{"width":4.91338582677165,"color":"rgba(70,130,180,1)","dash":"solid"},"hoveron":"points","name":"Amdahl","legendgroup":"Amdahl","showlegend":false,"xaxis":"x2","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[1,1.3,1.6,1.9,2.2,2.5,2.8,3.1,3.4,3.7,4,4.3,4.6,4.9,5.2],"text":["n_proc:  1<br />S:  1.000000<br />Tipo: Gustafson","n_proc:  2<br />S:  1.300000<br />Tipo: Gustafson","n_proc:  3<br />S:  1.600000<br />Tipo: Gustafson","n_proc:  4<br />S:  1.900000<br />Tipo: Gustafson","n_proc:  5<br />S:  2.200000<br />Tipo: Gustafson","n_proc:  6<br />S:  2.500000<br />Tipo: Gustafson","n_proc:  7<br />S:  2.800000<br />Tipo: Gustafson","n_proc:  8<br />S:  3.100000<br />Tipo: Gustafson","n_proc:  9<br />S:  3.400000<br />Tipo: Gustafson","n_proc: 10<br />S:  3.700000<br />Tipo: Gustafson","n_proc: 11<br />S:  4.000000<br />Tipo: Gustafson","n_proc: 12<br />S:  4.300000<br />Tipo: Gustafson","n_proc: 13<br />S:  4.600000<br />Tipo: Gustafson","n_proc: 14<br />S:  4.900000<br />Tipo: Gustafson","n_proc: 15<br />S:  5.200000<br />Tipo: Gustafson"],"type":"scatter","mode":"lines","line":{"width":4.91338582677165,"color":"rgba(205,92,92,1)","dash":"solid"},"hoveron":"points","name":"Gustafson","legendgroup":"Gustafson","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[1,1.7,2.4,3.1,3.8,4.5,5.2,5.9,6.6,7.3,8,8.7,9.4,10.1,10.8],"text":["n_proc:  1<br />S:  1.000000<br />Tipo: Gustafson","n_proc:  2<br />S:  1.700000<br />Tipo: Gustafson","n_proc:  3<br />S:  2.400000<br />Tipo: Gustafson","n_proc:  4<br />S:  3.100000<br />Tipo: Gustafson","n_proc:  5<br />S:  3.800000<br />Tipo: Gustafson","n_proc:  6<br />S:  4.500000<br />Tipo: Gustafson","n_proc:  7<br />S:  5.200000<br />Tipo: Gustafson","n_proc:  8<br />S:  5.900000<br />Tipo: Gustafson","n_proc:  9<br />S:  6.600000<br />Tipo: Gustafson","n_proc: 10<br />S:  7.300000<br />Tipo: Gustafson","n_proc: 11<br />S:  8.000000<br />Tipo: Gustafson","n_proc: 12<br />S:  8.700000<br />Tipo: Gustafson","n_proc: 13<br />S:  9.400000<br />Tipo: Gustafson","n_proc: 14<br />S: 10.100000<br />Tipo: Gustafson","n_proc: 15<br />S: 10.800000<br />Tipo: Gustafson"],"type":"scatter","mode":"lines","line":{"width":4.91338582677165,"color":"rgba(205,92,92,1)","dash":"solid"},"hoveron":"points","name":"Gustafson","legendgroup":"Gustafson","showlegend":false,"xaxis":"x2","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":63.3005371710826,"r":31.36,"b":70.2222665006227,"l":70.2222665006227},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"sans","size":14.6118721461187},"xaxis":{"domain":[0,0.494642857142857],"type":"linear","autorange":false,"tickmode":"array","range":[0.3,15.7],"ticktext":["4","8","12"],"tickvals":[4,8,12],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":6.98181818181818,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"tickangle":-0,"showline":true,"linecolor":"rgba(0,0,0,1)","linewidth":0.66417600664176,"showgrid":false,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"y","title":"","titlefont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"hoverformat":".2f"},"annotations":[{"text":"Número de processadores","x":0.5,"y":-0.0482689912826899,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"top","annotationType":"axis"},{"text":"Aceleração de processamento","x":-0.0344778509162071,"y":0.5,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"xref":"paper","yref":"paper","textangle":-90,"xanchor":"right","yanchor":"center","annotationType":"axis"},{"text":"P = 0.3","x":0.247321428571429,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9405371710826},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"},{"text":"P = 0.7","x":0.752678571428571,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9405371710826},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"center","yanchor":"bottom"}],"yaxis":{"domain":[0,1],"type":"linear","autorange":false,"tickmode":"array","range":[0.51,11.29],"ticktext":["3","6","9"],"tickvals":[3,6,9],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":6.98181818181818,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"tickangle":-90,"showline":true,"linecolor":"rgba(0,0,0,1)","linewidth":0.66417600664176,"showgrid":true,"gridcolor":"rgba(234,242,243,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"","titlefont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":0.494642857142857,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,230,235,1)","line":{"color":"transparent","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":0.494642857142857,"y0":1,"y1":1.0708675333018},{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0.505357142857143,"x1":1,"y0":0,"y1":1},{"type":"rect","fillcolor":"rgba(217,230,235,1)","line":{"color":"transparent","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0.505357142857143,"x1":1,"y0":1,"y1":1.0708675333018}],"xaxis2":{"type":"linear","autorange":false,"tickmode":"array","range":[0.3,15.7],"ticktext":["4","8","12"],"tickvals":[4,8,12],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":6.98181818181818,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"tickangle":-0,"showline":true,"linecolor":"rgba(0,0,0,1)","linewidth":0.66417600664176,"showgrid":false,"domain":[0.505357142857143,1],"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"y","title":"","titlefont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"hoverformat":".2f"},"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"rgba(0,0,0,1)","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":13.2835896909864},"y":0.917322061551491},"hovermode":"closest"},"source":"A","attrs":{"14ac2ea7a0f8":{"x":{},"y":{},"colour":{},"type":"ggplotly"}},"cur_data":"14ac2ea7a0f8","visdat":{"14ac2ea7a0f8":["function (y) ","x"]},"config":{"modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1}},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":{"render":[{"code":"function(el, x) { var ctConfig = crosstalk.var('plotlyCrosstalkOpts').set({\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1}}); }","data":null}]}}</script>
</center>
<p></br></p>
<p>Nota-se que a lei de Gustafson é menos pessimista que a lei de Amdahl quanto ao aumento de velocidade de processamento. De fato, a lei de Gustafson indica que a aceleração de processamento é linear no número de processadores enquanto que a lei de Amdahl é mais conservadora e tende a ser constante <span class="math inline">\(\left(S = \frac{1}{1-p}\right)\)</span> quando o número de processadores cresce.</p>
<p>Com estas leis é possível ter uma estimativa da melhora de performance de um código ao se utilizar computação paralela.</p>
<p>Porém, as vezes o custo computacional de se paralelizar o código pode ser maior que o ganho na velocidade de execução. Isso faz com que o custo computacional paralelizando o código seja maior do que o custo computacional sequencial. Este problema é conhecido como lentidão paralela.</p>
<p>Para exemplificar o fenômeno da lentidão paralela pense no seguinte exemplo: Você é um garçom em uma festa e tem trezentas taças para servir. Obviamente você não irá servir de uma em uma, então, com auxílio de uma bandeja você pode paralelizar o processo levando algumas taças. Porém, vai existir um número de taças na bandeja o qual o acrescimo de mais uma taça faz com que o processo de equilibrar a bandeja e servir mais complicado podendo inclusive provocar a queda da bandeja. Nesse caso a paralelização acaba sendo um problema e não uma solução.</p>
<p></br></p>
<center>
<img src="/rmarkdown-libs/figures-html/garcom.jpg" height="200px""/>
</center>
<p></br></p>
</div>
<div id="motivacao" class="section level2">
<h2><span style="color:#2f8fcc">Motivação</span></h2>
<p>Agora que já sabemos o que é computação paralela vamos à um exemplo prático. Vamos executar de tres formas diferentes o mesmo codigo. O comando <em>for</em> fará o <em>loop</em> usual (sequencial). O comando <em>foreach</em> em conjunto com o operador <em>%do%</em> também fará o <em>loop</em> sequencial. Já o comando <em>foreach</em> em conjunto com o operador <em>%dopar%</em> fará o <em>loop</em> em paralelo.</p>
<p>Para comparar os tempos de execução vamos utilizar a função <em>benchmark</em> do pacote <em>rbenchmark</em>.</p>
<pre class="r"><code>library(rbenchmark)
library(foreach)
library(parallel)
library(doMC)

registerDoMC(cores = detectCores())
sleep_time &lt;- 0.1      

bench &lt;- benchmark(&quot;for&quot; = for(i in 1:4){Sys.sleep(sleep_time)},                     # Sequencial
                   &quot;do&quot; = foreach(n = 1:4) %do% Sys.sleep(sleep_time),               # Sequencial
                   &quot;dopar&quot; = foreach(n = 1:4) %dopar% Sys.sleep(sleep_time),         # Paralelizado
                   columns = c(&quot;test&quot;, &quot;replications&quot;, 
                               &quot;elapsed&quot;, &quot;user.self&quot;, &quot;sys.self&quot;))
bench &lt;- bench[order(bench$elapsed),]
bench</code></pre>
<pre><code>##    test replications elapsed user.self sys.self
## 3 dopar          100  11.542     0.588    0.856
## 1   for          100  40.361     0.304    0.012
## 2    do          100  40.521     0.468    0.008</code></pre>
<p>Percebe-se que o custo computacional utilizando a função <em>foreach</em> paralelizada é muito menor que o custo associado ao <em>loop</em> sequencial. A função paralelizada tem um tempo de processamento de aproximadamente 11.542 segundos enquanto as demais tem tempos de execução de 40.361 e 40.521 (para realizar 100 replicações de um <em>loop</em> de 4 iterações).</p>
<p>Este é um exemplo simples em que cada passo da iteração tem um tempo computacional de aproximadamente 0.1 segundos. O resultado pode ser muito mais interessante quando pensarmos em um problema em que a função a ser executada dentro do <em>loop</em> tem um tempo computacional mais elevado.</p>
</div>
<div id="tipos-de-paralelismo" class="section level2">
<h2><span style="color:#2f8fcc">Tipos de paralelismo</span></h2>
<p>Existem várias formas de computação em paralelo. Neste documento vamos falar de dois tipos:</p>
<ul>
<li>Paralelismo utilizando os processadores de uma máquina.</li>
<li>Paralelismo utilizando uma placa gráfica (GPU).</li>
</ul>
</div>
<div id="paralelismo-utilizando-os-processadores-de-uma-maquina" class="section level2">
<h2><span style="color:#2f8fcc">Paralelismo utilizando os processadores de uma máquina</span></h2>
<p>A ideia básica é realizar processos simultâneamente e não sequencialmente. Para isso o procedimento a ser executado deve ser paralelizável e a máquina deve possuir mais do que um processador (o que é natural hoje em dia).</p>
<p>Para descobrir o número de processadores da sua máquina basta utilizar a função <em>detectCores</em> do pacote <em>parallel</em>,</p>
<pre class="r"><code>detectCores()</code></pre>
<pre><code>## [1] 4</code></pre>
<p>Desta forma, é possível realizar em paralelo 4 processos nesta máquina. Para ilustrar a paralelização vamos utilizar o pacote do R <em>foreach</em>.</p>
<div id="foreach" class="section level3">
<h3><span style="color:#2f8fcc"><em>foreach</em></span></h3>
<p>O pacote <em>foreach</em> possui uma forma diferente de executar códigos repetidamente no R. O principal diferencial do pacote é ter a opção de se realizar o <em>loop</em> em paralelo usando os processadores da sua máquina. Desta forma, operações que levam minutos utilizando a abordagem sequencial podem ser reduzidas à segundos de computação.</p>
<p>Primeiramente é interessante observar a forma como o pacote realiza o <em>loop</em> sequencial. Para isso utiliza-se o operador %do%, veja o exemplo abaixo:</p>
<pre class="r"><code>raiz &lt;- foreach(i=1:3) %do% sqrt(i)
raiz</code></pre>
<pre><code>## [[1]]
## [1] 1
## 
## [[2]]
## [1] 1.414214
## 
## [[3]]
## [1] 1.732051</code></pre>
<p>Perceba que por <em>default</em> a saída é uma lista, diferente do <em>loop</em> convencional (<em>for</em>) que retorna um vetor. De fato, o parâmetro <em>.combine</em> retorna o resultado do <em>loop</em> da maneira que o usuário achar mais adequado. Essa funcionalidade pode ser muito útil dependendo da aplicação.</p>
<pre class="r"><code>raiz_c &lt;- foreach(i=1:3, .combine = &#39;c&#39;) %do% sqrt(i)
raiz_c</code></pre>
<pre><code>## [1] 1.000000 1.414214 1.732051</code></pre>
<pre class="r"><code>raiz_rbind &lt;- foreach(i=1:3, .combine = &#39;rbind&#39;) %do% sqrt(i)
raiz_rbind</code></pre>
<pre><code>##              [,1]
## result.1 1.000000
## result.2 1.414214
## result.3 1.732051</code></pre>
<p>Para realizar o <em>loop</em> em paralelo utiliza-se o operador <em>dopar</em>. Além disso, é necessário criar um registro de quantos processadores serão utilizados no processamento. Esse registro pode ser feito utilizando o pacote <em>doMC</em>.</p>
<pre class="r"><code>registerDoMC(cores = detectCores())

n &lt;- 10
unif &lt;- runif(n = n)

system.time(
  foreach(i = 1:n, .combine = &#39;c&#39;) %do% {
    Sys.sleep(unif)
    i
  }
)</code></pre>
<pre><code>##    user  system elapsed 
##   0.008   0.000   4.250</code></pre>
<pre class="r"><code>system.time(
  foreach(i = 1:n, .combine = &#39;c&#39;) %dopar% {
    Sys.sleep(unif)
    i
  }
)</code></pre>
<pre><code>##    user  system elapsed 
##   0.004   0.016   1.284</code></pre>
<p>Com esse simples exemplo pode-se observar a grande diferença no tempo de execução entre o <em>loop</em> sequencial e o <em>loop</em> paralelizado.</p>
<p>Para mostrar a potencialidade da função vamos criar alguns exemplos. É interessante observarmos a diferença de tempo quando estamos trabalhando com algum processo custoso computacionalmente.</p>
<p>Normalmente em artigos, teses e dissertações em Estatística utilizam-se simulações extensivamente. Nestas simulações por muitas vezes variam-se alguns parâmetros do modelo e avaliam-se os resultados para cada configuração. Esse processo é chamado de análise de sensibilidade.</p>
<p>Neste sentido, vamos supor que temos acesso à <span class="math inline">\(n\)</span> covariáveis e vamos implementar um modelo de regressão linear para cada combinação possível dessas <span class="math inline">\(n\)</span> covariáveis (modelo guloso de seleção de covariáveis).</p>
<pre class="r"><code>library(mvtnorm)

nCov &lt;- 12                                           # 2^12 - 1 combinações
n &lt;- 10000
seq_n &lt;- 1:nCov
cov &lt;- data.frame(rmvnorm(n = n, mean = rep(0, nCov)))
data &lt;- cov
data$y &lt;- rnorm(n)
comb &lt;- Map(combn, list(seq_n), seq_along(seq_n), simplify = FALSE)
vars &lt;- unlist(comb, recursive = FALSE)

t1 &lt;- system.time(
  res_do &lt;- foreach(i = 1:(2^nCov - 1), .combine = &#39;rbind&#39;) %do% {
    formula &lt;- paste(&quot;y ~ &quot;, paste0(&quot;X&quot;, vars[[i]], collapse = &quot; + &quot;))
    reg &lt;- lm(formula = formula, data = data)
    df &lt;- data.frame(i = i, AIC = AIC(reg))
    df
  }
)

t1[3]</code></pre>
<pre><code>## elapsed 
##  70.693</code></pre>
<pre class="r"><code>t2 &lt;- system.time(
  res_dopar &lt;- foreach(i = 1:(2^nCov - 1), .combine = &#39;rbind&#39;) %dopar% {
    formula &lt;- paste(&quot;y ~ &quot;, paste0(&quot;X&quot;, vars[[i]], collapse = &quot; + &quot;))
    reg &lt;- lm(formula = formula, data = data)
    df &lt;- data.frame(i = i, AIC = AIC(reg))
    df
  }
)

t2[3]</code></pre>
<pre><code>## elapsed 
##  23.671</code></pre>
<p>Pode-se ver que o tempo de processamento do <em>loop</em> em paralelo é muito menor do que o <em>loop</em> sequencial. O tempo computacional do código paralelizado é igual a 33.48% do tempo computacional do código sequencial.</p>
<p>Neste caso 100% do código é paralelizável e desta forma as leis de Amdhal e Gustafson possuem a mesma estimativa de aceleração no tempo de execução. As estimativas de aceleração de ambas as leis é 4, desta forma espera-se que de fato, o código paralelizado seja 4 vezes mais rápido.</p>
<p>Outro contexto em que a paralelização pode ser útil é quando temos um modelo de aprendizado de máquina com diversos parâmetros de tunagem. Em geral testa-se algumas configurações destes parâmetros e escolhe-se o modelo que minimiza alguma função objetivo. Para ilustrar esse caso vamos utilizar o modelo SVM para classificação.</p>
<p>Para ajustar um modelo de SVM no R vamos utilizar a função <em>svm</em> do pacote <em>e1071</em>. Os hiperparâmetros que serão variados serão: <em>scale</em>, <em>kernel</em>, <em>degree</em>, <em>gamma</em> e <em>cost</em>. Para melhor entendimento dos parâmetros veja <em>?e1071::svm</em>.</p>
<pre class="r"><code>library(e1071)

#--- Criando uma base de dados
nCov &lt;- 10
n &lt;- 5000
X &lt;- rmvnorm(n = n, mean = rep(0, nCov))
betas &lt;- rnorm(n = nCov)
Xbeta &lt;- X%*%betas 
y &lt;- ifelse(Xbeta &lt; 0.5, 0, 1)
data &lt;- data.frame(y = y, X)
#--- Separando a base em treino e teste
id &lt;- 1:nrow(data)
testindex &lt;- sample(id, trunc(length(id)/3))
testset &lt;- data[testindex,]
trainset &lt;- data[-testindex,]
#--- Criando os grids para avaliação dos parâmetros de tunagem
scale = c(TRUE, FALSE)
kernel = c(&quot;linear&quot;, &quot;polynomial&quot;, &quot;radial&quot;, &quot;sigmoid&quot;)
degree = 2:4
gamma = 1/seq(nrow(trainset)-(n/10), nrow(trainset) + (n/10), length.out = 4)
cost = seq(1, 10, length.out = 4)
parameters &lt;- expand.grid(scale = scale, 
                          kernel = kernel, 
                          degree = degree,
                          gamma = gamma,
                          cost = cost)
#--- SVM sem paralelização
t1 &lt;- system.time(
  svm.output_1 &lt;- foreach(i = 1:nrow(parameters), .combine = &#39;rbind&#39;) %do% {
  #--- Modelo
  svm.model &lt;- svm(formula = y ~ .,                     
                   data = trainset, 
                   scale = parameters[i, 1], 
                   kernel = parameters[i, 2], 
                   degree = parameters[i, 3], 
                   gamma = parameters[i, 4], 
                   cost = parameters[i, 5],
                   type = &quot;C-classification&quot;)
  #--- Predição
  svm.pred &lt;- predict(svm.model, testset[,-1])
  #--- Métrica de acurácia
  svm.confusao &lt;- table(pred = svm.pred, true = testset[,1])
  svm.acuracia &lt;- sum(diag(svm.confusao))/sum(svm.confusao)
  #--- Retornando os resultados
  cbind(parameters[i,], acuracia = svm.acuracia)
}
)
#--- SVM com paralelização
t2 &lt;- system.time(
  svm.output_2 &lt;- foreach(i = 1:nrow(parameters), .combine = &#39;rbind&#39;) %dopar% {
  #--- Modelo
  svm.model &lt;- svm(formula = y ~ .,
                   data = trainset, 
                   scale = parameters[i, 1], 
                   kernel = parameters[i, 2], 
                   degree = parameters[i, 3], 
                   gamma = parameters[i, 4], 
                   cost = parameters[i, 5],
                   type = &quot;C-classification&quot;)
  #--- Predição
  svm.pred &lt;- predict(svm.model, testset[,-1])
  #--- Métrica de acurácia
  svm.confusao &lt;- table(pred = svm.pred, true = testset[,1])
  svm.acuracia &lt;- sum(diag(svm.confusao))/sum(svm.confusao)
  #--- Retornando os resultados
  cbind(parameters[i,], acuracia = svm.acuracia)
}
)
t1[3]</code></pre>
<pre><code>## elapsed 
## 437.024</code></pre>
<pre class="r"><code>t2[3]</code></pre>
<pre><code>## elapsed 
## 122.245</code></pre>
<pre class="r"><code>all.equal(svm.output_1, svm.output_2) </code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>best.config &lt;- svm.output_2[which.max(svm.output_2$acuracia), ]
best.config</code></pre>
<pre><code>##     scale kernel degree        gamma cost  acuracia
## 193  TRUE linear      2 0.0003528582    7 0.9981993</code></pre>
<p>Neste problema vemos que o código com a paralelização teve um tempo computacional equivalente a 27.97% do tempo computacional da versão não paralelizada. O que neste contexto reflete em um ganho de 5.2463 minutos no tempo de processamento.</p>
<p>Pensando nas leis de <em>Amdahl</em> e <em>Gustafson</em> (ambas resultariam em uma aceleração de 4 vezes para este caso em que o código é 100% paralelizável) a estimativa para a aceleração no tempo de execução do código é acertiva.</p>
<p>Abaixo temos duas figuras, uma mostrando o uso dos processadores enquanto o <em>loop</em> sequencial rodava e outra enquanto o <em>loop</em> paralelizado rodava. É possível perceber que de fato o <em>loop</em> sequencial utiliza apenas um processador enquanto o <em>loop</em> paralelizado utiliza todo o potencial computacional.</p>
<center>
<div class="figure">
<img src="/rmarkdown-libs/figures-html/NaoPar.jpg" alt="Processadores durante o loop não paralelizado" />
<p class="caption">Processadores durante o loop não paralelizado</p>
</div>
<div class="figure">
<img src="/rmarkdown-libs/figures-html/Par.jpg" alt="Processadores durante o loop paralelizado" />
<p class="caption">Processadores durante o loop paralelizado</p>
</div>
</center>
<p>Com isso, é interessante ressaltar que quanto maior o número de processadores maior o ganho ao se paralelizar um código.</p>
<p>Uma ideia interessante é investigar o que ocorre quando declararamos mais processadores do que o próprio número de processadores da máquina. Isto pode fazer sentido quando o processo a ser executado consome pouco processamento. Obviamente, declarando muito mais processadores do que o número existente podemos cair num problema de lentidão paralela (exemplo do garçom). No exemplo abaixo temos a comparação dos tempos de execução considerando diferentes números de processadores (lembrando que a minha máquina possui 4 processadores).</p>
<pre class="r"><code>function_test &lt;- function(cores, X = rmvnorm(n = 2000, mean = rep(0, 50)), sleep.time = 0.0001, n){
  #--- Registrando o número de processadores
  registerDoMC(cores = cores)
  #--- Loop
  foreach(i = 1:n, .combine = &#39;c&#39;) %dopar% {
    #--- Custo de processamento
    result &lt;- X%*%t(X)
    #--- Custo de tempo
    Sys.sleep(sleep.time)
  }
} 
X = rmvnorm(n = 150, mean = rep(0, 150))
sleep.time &lt;- 1.5*system.time(X%*%t(X))
n &lt;- 100

t001 &lt;- system.time(function_test(cores = 1, X = X, sleep.time = sleep.time, n = n))[3]
t002 &lt;- system.time(function_test(cores = 2, X = X, sleep.time = sleep.time, n = n))[3]
t004 &lt;- system.time(function_test(cores = 4, X = X, sleep.time = sleep.time, n = n))[3]           
t008 &lt;- system.time(function_test(cores = 8, X = X, sleep.time = sleep.time, n = n))[3]
t016 &lt;- system.time(function_test(cores = 16, X = X, sleep.time = sleep.time, n = n))[3]
t025 &lt;- system.time(function_test(cores = 25, X = X, sleep.time = sleep.time, n = n))[3]
t032 &lt;- system.time(function_test(cores = 32, X = X, sleep.time = sleep.time, n = n))[3]
t050 &lt;- system.time(function_test(cores = 50, X = X, sleep.time = sleep.time, n = n))[3]
t064 &lt;- system.time(function_test(cores = 64, X = X, sleep.time = sleep.time, n = n))[3]
t075 &lt;- system.time(function_test(cores = 75, X = X, sleep.time = sleep.time, n = n))[3]
t090 &lt;- system.time(function_test(cores = 90, X = X, sleep.time = sleep.time, n = n))[3]
t100 &lt;- system.time(function_test(cores = 100, X = X, sleep.time = sleep.time, n = n))[3]

tempos &lt;- data.frame(tempos = c(t001, t002, t004, 
                                t008, t016, t025, 
                                t032, t050, t064, 
                                t075, t090, t100),
                     processadores = c(1, 2, 4, 8,
                                       16, 25, 32,
                                       50, 64, 75,
                                       90, 100))

tempos</code></pre>
<pre><code>##    tempos processadores
## 1   0.885             1
## 2   0.474             2
## 3   0.251             4
## 4   0.146             8
## 5   0.141            16
## 6   0.149            25
## 7   0.151            32
## 8   0.178            50
## 9   0.208            64
## 10  0.247            75
## 11  0.283            90
## 12  0.331           100</code></pre>
<p>Não utilizei a função <em>benchmark</em> para garantir que em nenhum momento houvessem processos concorrentes. Vejamos graficamente o que ocorreu nesta simulação:</p>
<pre class="r"><code>ggTime &lt;- ggplot(data = tempos, aes(x = processadores, y = tempos)) +
  geom_line(col = colLine, size = sizeLine) + 
  geom_point(col = colPoints, size = sizePoint) +
  xlab(&quot;Número de processadores&quot;) +
  ylab(&quot;Tempo de processamento&quot;) +
  tema

ggplotly(ggTime)</code></pre>
<pre><code>## Warning: We recommend that you use the dev version of ggplot2 with `ggplotly()`
## Install it with: `devtools::install_github(&#39;hadley/ggplot2&#39;)`</code></pre>
<center>
<pre><code>## Warning: We recommend that you use the dev version of ggplot2 with `ggplotly()`
## Install it with: `devtools::install_github(&#39;hadley/ggplot2&#39;)`</code></pre>
<div id="14ac6dafbf50" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="14ac6dafbf50">{"x":{"data":[{"x":[1,2,4,8,16,25,32,50,64,75,90,100],"y":[0.884999999999991,0.473999999999933,0.250999999999976,0.145999999999958,0.140999999999963,0.149000000000001,0.150999999999954,0.177999999999997,0.20799999999997,0.246999999999957,0.283000000000015,0.331000000000017],"text":["processadores:   1<br />tempos: 0.885","processadores:   2<br />tempos: 0.474","processadores:   4<br />tempos: 0.251","processadores:   8<br />tempos: 0.146","processadores:  16<br />tempos: 0.141","processadores:  25<br />tempos: 0.149","processadores:  32<br />tempos: 0.151","processadores:  50<br />tempos: 0.178","processadores:  64<br />tempos: 0.208","processadores:  75<br />tempos: 0.247","processadores:  90<br />tempos: 0.283","processadores: 100<br />tempos: 0.331"],"type":"scatter","mode":"markers+lines","line":{"width":4.91338582677165,"color":"rgba(205,92,92,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","marker":{"autocolorscale":false,"color":"rgba(11,83,148,1)","opacity":1,"size":7.55905511811024,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(11,83,148,1)"}},"frame":null}],"layout":{"margin":{"t":47.36,"r":31.36,"b":70.2222665006227,"l":70.2222665006227},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"sans","size":14.6118721461187},"xaxis":{"domain":[0,1],"type":"linear","autorange":false,"tickmode":"array","range":[-3.95,104.95],"ticktext":["0","25","50","75","100"],"tickvals":[-4.44089209850063e-16,25,50,75,100],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":6.98181818181818,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"tickangle":-0,"showline":true,"linecolor":"rgba(0,0,0,1)","linewidth":0.66417600664176,"showgrid":false,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"y","title":"Número de processadores","titlefont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"type":"linear","autorange":false,"tickmode":"array","range":[0.103799999999961,0.922199999999992],"ticktext":["0.25","0.50","0.75"],"tickvals":[0.25,0.5,0.75],"ticks":"outside","tickcolor":"rgba(0,0,0,1)","ticklen":6.98181818181818,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"tickangle":-90,"showline":true,"linecolor":"rgba(0,0,0,1)","linewidth":0.66417600664176,"showgrid":true,"gridcolor":"rgba(234,242,243,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":"Tempo de processamento","titlefont":{"color":"rgba(0,0,0,1)","family":"sans","size":15.9402241594022},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"rgba(0,0,0,1)","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"sans","size":13.2835896909864}},"hovermode":"closest"},"source":"A","attrs":{"14ac5cb5295f":{"x":{},"y":{},"type":"ggplotly"},"14acf0d7a04":{"x":{},"y":{}}},"cur_data":"14ac5cb5295f","visdat":{"14ac5cb5295f":["function (y) ","x"],"14acf0d7a04":["function (y) ","x"]},"config":{"modeBarButtonsToAdd":[{"name":"Collaborate","icon":{"width":1000,"ascent":500,"descent":-50,"path":"M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z"},"click":"function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }"}],"cloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1}},"base_url":"https://plot.ly"},"evals":["config.modeBarButtonsToAdd.0.click"],"jsHooks":{"render":[{"code":"function(el, x) { var ctConfig = crosstalk.var('plotlyCrosstalkOpts').set({\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1}}); }","data":null}]}}</script>
</center>
<p>É possível ver que o tempo de execução tende a decrescer até o momento em que consideramos 16 processadores. Depois deste ponto o tempo computacional começa a crescer (inclusive podendo ser menos vantajoso que o <em>loop</em> sequencial). Obviamente o interessante seria realizar um processo similar ao realizado pelo <em>benchmark</em>, ou seja, executar algumas vezes o mesmo processo e em seguida observar alguma medida de tendência central para melhor representar o custo computacional do processo.</p>
<p>Diversos outros pacotes do R se propõe a realizar a paralelização tal como o pacote <em>snow</em> e o pacote <em>parallel</em>. Porém, o pacote <em>foreach</em> parece atender bem às expectativas além de ser muito simples e intuitivo.</p>
<p>Atualmente o tipo de paralelismo mais utilizado e com melhores resultados é o paralelismo utilizando placas gráficas (GPU) que vamos discutir a seguir.</p>
</div>
</div>
<div id="paralelismo-utilizando-uma-placa-grafica" class="section level2">
<h2><span style="color:#2f8fcc">Paralelismo utilizando uma placa gráfica</span></h2>
<p>Em sua origem na década de 70, a placa gráfica (ou placa de vídeo) era um componente utilizado simplesmente para aumentar a velocidade de apresentação de imagens em jogos <em>arcade</em>.</p>
<p></br></p>
<center>
<img src="/rmarkdown-libs/figures-html/space-invaders.jpg" height="100px""/>
</center>
<p></br></p>
<p>Depois de vários avanços, as placas de vídeo passaram a ser utilizadas em outros contextos, especialmente em <em>Machine Learning</em>. Desde então os fabricantes de placas gráficas não se preocupam só em criar placas voltadas para <em>games</em> ou <em>softwares</em> 3D e sim placas especiais (e caras) utilizadas para aprendizado de máquina. Mas porquê?</p>
<p>Um vídeo bastante motivador que tenta explicar as diferenças entre processamento utilizando os <em>cores</em> do computador e o processamento utilizando uma placa gráfica pode ser visto abaixo.</p>
<p></br></p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-P28LKWTzrI" frameborder="0" allowfullscreen>
</iframe>
</center>
<p></br></p>
<p>Apesar do exagero, a programação utilizando <em>Graphics Processing Unit</em> (GPU) pode ser extremamente mais eficiente do que a programação utilizando os processadores da máquina. Isso pois um computador possui um número limitado de processadores (grandes) pensados e otimizados para processamentos sequenciais. Já uma GPU é idelizada justamente para realizar processos em paralelo, desta forma são milhares de pequenos processadores otimizados para computação paralela (este tipo de computação também é chamada de <em>General Purpose Graphics Processing Unit</em> - GPGPU).</p>
<center>
<figure>
<img src="/rmarkdown-libs/figures-html/cpu-vs-gpu.jpg">
<figcaption>
CPU vs GPU. Fonte: NVIDIA
</figcaption>
</figure>
</center>
<p></br></p>
<p>Como nem tudo são flores, a programação utilizando GPU tem a sua limitação. A maioria das placas existentes não possui muita memória o que implica em processamento de pequenas quantidades de dados. Desta forma o processo deve ser raduzido à pequenas subtarefas que não exijam muita memória.</p>
<p>Um simples exemplo de processo paralelizável em GPU é o produto matricial. Na verdade o produto matricial pode ser pensado como produto independente de linhas e colunas. Cada entrada da matriz resposta é na verdade o produto de uma linha por uma coluna, termo a termo, somados. Desta forma, o produto de uma matriz de 1000 linhas e 1000 colunas por outra matriz de mesma dimensão pode ser pensada como 1000*1000 processos independentes. Em cada um dos processos temos apenas dois vetores de dimensão 1000 multiplicados e em seguida somados.</p>
<p>Ou seja, o problema pode ser resolvido de forma mais eficiente. Resolvendo esse problema de forma sequencial teríamos de realizar 1.000.000 de iterações. Ao se paralelizar esse problema num computador com 4 processadores poderíamos diminuir o tempo computacional para algo em torno de 25% do tempo gasto pelo codigo sequencial. E ao se utilizar uma GPU? as GPUs contam com milhares de processadores, desta forma o tempo de computação pode ser reduzido à um tempo irrisório.</p>
<p>Existem no mercado uma enorme variedade de placas de vídeo e atualmente existem placas desenhadas especialmente para processamento em paralelo. Algumas delas (mais caras) possuem inclusive uma memória maior, permitindo ao usuário executar processos mais complexos e que exigem maior espaço para alocação.</p>
<p>Na ausência de uma placa de vídeo me atenho aos exemplos realizados por sortudos que à possuem. Neste site temos acesso à diversos exemplos aos quais o tempo computacional utilizando CPU e utilizando GPU são comparados: <a href="http://www.r-tutor.com/gpu-computing">Computação em GPU</a>.</p>
<p>Em resumo os exemplos mostram (no R, utilizando o pacote <em>rpud</em>) uma melhora impressionante no tempo de execução dos códigos. Apenas para reforçar a mensagem atente para o exemplo do <a href="http://www.r-tutor.com/gpu-computing/clustering/hierarchical-cluster-analysis"><em>cluster</em> hierárquico</a>. O tempo de execução utilizando a função paralelizada em GPU foi extremamente mais rápida se reduzindo a menos de cinco segundos enquanto a função original leva mais de um minuto (Caso de 4000 vetores).</p>
<p>Obviamente utilizar a programação em GPU é um bom negócio, portanto de posse de uma placa experimente melhorar a performance do seu código.</p>
</div>
<div id="referencias" class="section level2">
<h2><span style="color:#2f8fcc">Referências</span></h2>
<p><a href="https://en.wikipedia.org/wiki/Parallel_computing" class="uri">https://en.wikipedia.org/wiki/Parallel_computing</a></p>
<p><a href="https://www.r-bloggers.com/how-to-go-parallel-in-r-basics-tips/" class="uri">https://www.r-bloggers.com/how-to-go-parallel-in-r-basics-tips/</a></p>
<p><a href="http://blog.aicry.com/r-parallel-computing-in-5-minutes/" class="uri">http://blog.aicry.com/r-parallel-computing-in-5-minutes/</a></p>
<p><a href="https://computing.llnl.gov/tutorials/parallel_comp/" class="uri">https://computing.llnl.gov/tutorials/parallel_comp/</a></p>
<p><a href="https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf" class="uri">https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf</a></p>
<p><a href="https://www.r-bloggers.com/the-wonders-of-foreach/" class="uri">https://www.r-bloggers.com/the-wonders-of-foreach/</a></p>
<p><a href="ftp://cran.r-project.org/pub/R/web/packages/foreach/vignettes/foreach.pdf" class="uri">ftp://cran.r-project.org/pub/R/web/packages/foreach/vignettes/foreach.pdf</a></p>
<p><a href="https://cran.r-project.org/web/packages/foreach/foreach.pdf" class="uri">https://cran.r-project.org/web/packages/foreach/foreach.pdf</a></p>
<p><a href="http://www.nvidia.com/object/what-is-gpu-computing.html" class="uri">http://www.nvidia.com/object/what-is-gpu-computing.html</a></p>
<p><a href="http://www.r-tutor.com/gpu-computing" class="uri">http://www.r-tutor.com/gpu-computing</a></p>
</div>
</div>
